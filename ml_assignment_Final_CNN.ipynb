{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "ml_assignment_Final_CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jason-Oleana/written-spoken-digits-cnn-classification/blob/master/ml_assignment_Final_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0XDMXa--a5D",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh1di7G9-a5E",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7vorEJ5-a5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split  \n",
        "from scipy.stats import kurtosis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyN9Pqcx-a5H",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q_j86CU-a5I",
        "colab_type": "code",
        "outputId": "f68dae0a-4c4e-4808-ac63-89fdfac5749e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "written_train = numpy.load(\"/content/drive/My Drive/Data Science/machine learning/written_train(1).npy\", allow_pickle=True)\n",
        "spoken_train = numpy.load(\"/content/drive/My Drive/Data Science/machine learning/spoken_train(1).npy\", allow_pickle=True)\n",
        "match_train = numpy.load(\"/content/drive/My Drive/Data Science/machine learning/match_train(1).npy\", allow_pickle=True)\n",
        "\n",
        "print(\"written train shape:\", written_train.shape)\n",
        "print(\"spoken train shape:\", spoken_train.shape)\n",
        "print(\"match train shape:\", match_train.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "written train shape: (45000, 784)\n",
            "spoken train shape: (45000,)\n",
            "match train shape: (45000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A3160S1_Ctm",
        "colab_type": "code",
        "outputId": "10326c84-0045-4f21-c0aa-3f0a4269917a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJpo6rCo-a5K",
        "colab_type": "code",
        "outputId": "88371987-1bc5-471e-8277-f9ac6804388a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "largest_shape = 0\n",
        "for i in spoken_train:\n",
        "    shape = i.shape[0]\n",
        "    if shape > largest_shape:\n",
        "        largest_shape = shape\n",
        "\n",
        "print(largest_shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk13xKrO-a5M",
        "colab_type": "code",
        "outputId": "2c2d36d5-0263-421a-d0ac-84a28fe7b27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_spoken_train = []\n",
        "for example in spoken_train:\n",
        "    difference = largest_shape-example.shape[0]\n",
        "    zero_pad = numpy.pad(example,((0,difference),(0,0)), mode='constant')\n",
        "    new_spoken_train.append(zero_pad)\n",
        "\n",
        "new_spoken_train = numpy.array(new_spoken_train)\n",
        "new_spoken_train.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 93, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMsLjNrW-a5O",
        "colab_type": "code",
        "outputId": "b4fea139-3095-4bbb-905e-7ef7867f7fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(93*13)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDETI6iI-a5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spoken_train = new_spoken_train\n",
        "spoken_train = numpy.reshape(spoken_train,(45000,1209))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kca8m5jG-a5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(spoken_train)\n",
        "spoken_train = scaler.transform(spoken_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekdS357Q-a5T",
        "colab_type": "text"
      },
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "- divide written_train by 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnvL7y9f-a5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_written = written_train/255\n",
        "X_spoken = spoken_train\n",
        "y = match_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2CRbSxh-a5V",
        "colab_type": "text"
      },
      "source": [
        "## Label distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d1A9zzvz-a5W",
        "colab_type": "code",
        "outputId": "a8133e99-5b6b-433b-cb25-0a70a3956d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "total = len(y)\n",
        "positives = sum(y)\n",
        "negatives = total - positives\n",
        "\n",
        "print(\"number of total rows: {}\".format(total))\n",
        "print(\"number of positives: {} ({}%)\".format(positives, round((positives/total)*100,2)))\n",
        "print(\"number of negatives: {} ({}%)\".format(negatives, round((negatives/total)*100,2)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of total rows: 45000\n",
            "number of positives: 4539 (10.09%)\n",
            "number of negatives: 40461 (89.91%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymFd_DD7-a5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_written = numpy.reshape(X_written,(45000,784))\n",
        "X_spoken = numpy.reshape(X_spoken,(45000,1209))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeAKUTdg-a5l",
        "colab_type": "code",
        "outputId": "a674510d-cb2d-438c-d545-27b20dd26528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_written, y1 = oversampler.fit_resample(X_written, y)\n",
        "X_spoken, y2 = oversampler.fit_resample(X_spoken, y)\n",
        "print('Resampled dataset shape %s' % Counter(y2))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({False: 40461, True: 40461})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqFrWlgrALOf",
        "colab_type": "code",
        "outputId": "bbe43e1f-97a2-40c1-bcb6-51d2865685e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "values = array(y2)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False False False ...  True  True  True]\n",
            "[0 0 0 ... 1 1 1]\n",
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "[False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR6hz7ODAI6B",
        "colab_type": "code",
        "outputId": "c00a3add-3980-404e-e8cc-ce071be3f6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(X_written.shape)\n",
        "print(X_spoken.shape)\n",
        "print(y2.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80922, 784)\n",
            "(80922, 1209)\n",
            "(80922,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EReMjbpt-a5n",
        "colab_type": "text"
      },
      "source": [
        "# step 1: split data in training and validation:\n",
        "- written train split: 80% train, 20% validation\n",
        "<br>\n",
        "- spoken train split: 80% train, 20% validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY9TudTB-a5n",
        "colab_type": "text"
      },
      "source": [
        "Since the data is imbalanced, we use stratify to make sure the distribution of labels is the same in our train and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ZqU6gM-a5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_written_train, X_written_test, X_spoken_train, X_spoken_test, y_train, y_valid = train_test_split(X_written, X_spoken, y2, test_size=0.20, stratify = y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUCh1DC_9nQc",
        "colab_type": "code",
        "outputId": "9c7d6606-ae3a-4f4d-bf05-b18e812d6130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_written_test.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16185, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoC2lO2MAkfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_written_test = numpy.reshape(X_written_test,(X_written_test.shape[0],28,28))\n",
        "X_written_train = numpy.reshape(X_written_train,(X_written_train.shape[0],28,28))\n",
        "X_spoken_test = numpy.reshape(X_spoken_test,(X_spoken_test.shape[0],93,13))\n",
        "X_spoken_train = numpy.reshape(X_spoken_train,(X_spoken_train.shape[0],93,13))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXyLGF8wRSiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "46e7aa15-e089-4e33-d714-bf2bbcc4339f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
        "#create model\n",
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "input1 = keras.layers.Input(shape=(28,28))\n",
        "x1 = keras.layers.Conv1D(32, 2, activation='relu')(input1)\n",
        "x1 = keras.layers.MaxPooling1D(2)(x1)\n",
        "x2 = keras.layers.Conv1D(32, 2, activation='relu')(x1)\n",
        "#x2 = keras.layers.MaxPooling1D(2)(x2)\n",
        "x3 = keras.layers.Flatten()(x2)\n",
        "input2 = keras.layers.Input(shape=(93,13))\n",
        "y1 = keras.layers.Conv1D(32, 2, activation='relu')(input2)\n",
        "y1 = keras.layers.MaxPooling1D(2)(y1)\n",
        "y2 = keras.layers.Conv1D(32, 2, activation='relu')(y1)\n",
        "#y2 = keras.layers.MaxPooling1D(2)(y2)\n",
        "y3 = keras.layers.Flatten()(y2)\n",
        "# Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "concatenate = keras.layers.Concatenate()([x3, y3])\n",
        "Dense_1 = Dense(100, activation='relu')(concatenate)\n",
        "Dense_2 = Dense(100, activation='relu')(Dense_1)\n",
        "out = keras.layers.Dense(1, activation = \"sigmoid\")(Dense_2)\n",
        "model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, 28, 28)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 93, 13)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_25 (Conv1D)              (None, 27, 32)       1824        input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_27 (Conv1D)              (None, 92, 32)       864         input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling1D) (None, 13, 32)       0           conv1d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling1D) (None, 46, 32)       0           conv1d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_26 (Conv1D)              (None, 12, 32)       2080        max_pooling1d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_28 (Conv1D)              (None, 45, 32)       2080        max_pooling1d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 384)          0           conv1d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 1440)         0           conv1d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 1824)         0           flatten_13[0][0]                 \n",
            "                                                                 flatten_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 100)          182500      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 100)          10100       dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 1)            101         dense_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 199,549\n",
            "Trainable params: 199,549\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atkojHJ5RU7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit([X_written_train, X_spoken_train], y_train,\n",
        "                    epochs=150, validation_split=0.20, batch_size=64, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwhufTvm-a57",
        "colab_type": "text"
      },
      "source": [
        "Check if the labels are indeed distributed equally\n",
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzPTo2uL-a58",
        "colab_type": "code",
        "outputId": "04dcc62f-2121-4d4d-f9ed-8884fa71196f",
        "colab": {}
      },
      "source": [
        "total = len(y_train)\n",
        "positives = sum(y_train)\n",
        "negatives = total - positives\n",
        "\n",
        "print(\"number of total rows: {}\".format(total))\n",
        "print(\"number of positives: {} ({}%)\".format(positives, round((positives/total)*100,2)))\n",
        "print(\"number of negatives: {} ({}%)\".format(negatives, round((negatives/total)*100,2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of total rows: 36000\n",
            "number of positives: 3631 (10.09%)\n",
            "number of negatives: 32369 (89.91%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a9PjymI-a59",
        "colab_type": "text"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCw3Lxxd-a5-",
        "colab_type": "code",
        "outputId": "e4c5b5d2-7884-4787-e680-10db13811321",
        "colab": {}
      },
      "source": [
        "total = len(y_valid)\n",
        "positives = sum(y_valid)\n",
        "negatives = total - positives\n",
        "\n",
        "print(\"number of total rows: {}\".format(total))\n",
        "print(\"number of positives: {} ({}%)\".format(positives, round((positives/total)*100,2)))\n",
        "print(\"number of negatives: {} ({}%)\".format(negatives, round((negatives/total)*100,2)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of total rows: 9000\n",
            "number of positives: 908 (10.09%)\n",
            "number of negatives: 8092 (89.91%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJmqiRqY-a6A",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing / Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LiVrzJ8-a6A",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: feature engineering for written data:\n",
        "- written training data\n",
        "<br>\n",
        "- written validation data\n",
        "<br>\n",
        "Extract mean, min, max, std, count for written"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sBuz8N-a6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_summary_stats_written(X_written):\n",
        "#.........................................\n",
        "    #look at summaries list, mean, min, max, std are functions in function_list\n",
        "    \n",
        "    written_mean = []\n",
        "    written_min = []\n",
        "    written_max = []\n",
        "    written_std = [] \n",
        "    written_kurtosis = []\n",
        "    \n",
        "    for element in X_written:\n",
        "        written_mean.append(numpy.mean(element))\n",
        "        written_min.append(numpy.min(element))\n",
        "        written_max.append(numpy.max(element))\n",
        "        written_std.append(numpy.std(element))\n",
        "        written_kurtosis.append(kurtosis(element))\n",
        "        \n",
        "        \n",
        "    return written_mean, written_min, written_max, written_std, written_kurtosis\n",
        "#-----------------------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H-XeJOy-a6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_written_preproc = extract_summary_stats_written(X_written_train)\n",
        "X_valid_written_preproc = extract_summary_stats_written(X_written_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNS9Ixtf-a6E",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: feature engineering for spoken data:\n",
        "\n",
        "- spoken training data \n",
        "<br>\n",
        "- spoken validation data \n",
        "<br>\n",
        "Extract mean, min, max, std for spoken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knIGbbbA-a6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_summary_stats_spoken(X_spoken):\n",
        "#.........................................\n",
        "    #look at summaries list, mean, min, max, std are functions in function_list\n",
        "    spoken_mean = []\n",
        "    spoken_min = []\n",
        "    spoken_max = []\n",
        "    spoken_std = []\n",
        "    spoken_kurtosis = []\n",
        "    for element in X_spoken:\n",
        "        spoken_mean.append(numpy.mean(element))\n",
        "        spoken_min.append(numpy.min(element))\n",
        "        spoken_max.append(numpy.max(element))\n",
        "        spoken_std.append(numpy.std(element))\n",
        "        spoken_kurtosis.append(numpy.mean(kurtosis(element)))\n",
        "    \n",
        "    print(spoken_kurtosis[0])\n",
        "    return spoken_mean, spoken_min, spoken_max, spoken_std, spoken_kurtosis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBV5MtEL-a6G",
        "colab_type": "code",
        "outputId": "492d4a81-a9eb-40cf-85f5-f326007b0ae6",
        "colab": {}
      },
      "source": [
        "X_train_spoken_preproc = extract_summary_stats_spoken(X_spoken_train)\n",
        "X_valid_spoken_preproc = extract_summary_stats_spoken(X_spoken_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.109109030524278\n",
            "4.342230936714155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pss0dhQj-a6I",
        "colab_type": "text"
      },
      "source": [
        "# Extract all summaries from written & spoken feature engineering data function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAspDvmd-a6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "written_mean, written_min, written_max, written_std, written_kurtosis = X_train_written_preproc\n",
        "written_val_mean, written_val_min, written_val_max, written_val_std, written_val_kurtosis = X_valid_written_preproc\n",
        "\n",
        "spoken_mean, spoken_min, spoken_max, spoken_std, spoken_kurtosis = X_train_spoken_preproc\n",
        "spoken_val_mean, spoken_val_min, spoken_val_max, spoken_val_std, spoken_val_kurtosis = X_valid_spoken_preproc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUq9vleP-a6L",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: use summaries to Build a dataframe for:\n",
        "- training set\n",
        "<br>\n",
        "- validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dmcg9sc-a6L",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bJ7Qe_x-a6M",
        "colab_type": "code",
        "outputId": "5989385a-0801-47d3-ae7a-7bf6f0d088e9",
        "colab": {}
      },
      "source": [
        "X_train_final_cols = {'written_mean':pd.Series(written_mean),\n",
        "                      'written_min':pd.Series(written_min),\n",
        "                      'written_max':pd.Series(written_max),\n",
        "                      'written_std':pd.Series(written_std),\n",
        "                      'written_kurtosis':pd.Series(written_kurtosis),\n",
        "                      'spoken_mean':pd.Series(spoken_mean),\n",
        "                      'spoken_min':pd.Series(spoken_min),\n",
        "                      'spoken_max':pd.Series(spoken_max), \n",
        "                      'spoken_std':pd.Series(spoken_std),\n",
        "                      'spoken_kurtosis':pd.Series(spoken_kurtosis)}\n",
        "\n",
        "X_train_final = pd.DataFrame(X_train_final_cols)\n",
        "X_train_final.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spoken_kurtosis</th>\n",
              "      <th>spoken_max</th>\n",
              "      <th>spoken_mean</th>\n",
              "      <th>spoken_min</th>\n",
              "      <th>spoken_std</th>\n",
              "      <th>written_kurtosis</th>\n",
              "      <th>written_max</th>\n",
              "      <th>written_mean</th>\n",
              "      <th>written_min</th>\n",
              "      <th>written_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.109109</td>\n",
              "      <td>3.746517</td>\n",
              "      <td>0.037989</td>\n",
              "      <td>-2.907489</td>\n",
              "      <td>0.640406</td>\n",
              "      <td>6.258335</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.908298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.252658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.147835</td>\n",
              "      <td>3.410470</td>\n",
              "      <td>0.142919</td>\n",
              "      <td>-2.815631</td>\n",
              "      <td>0.707371</td>\n",
              "      <td>1.328988</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.830687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.334427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.937611</td>\n",
              "      <td>3.167490</td>\n",
              "      <td>0.038646</td>\n",
              "      <td>-3.934161</td>\n",
              "      <td>0.699209</td>\n",
              "      <td>1.112804</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.824165</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.347787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.697519</td>\n",
              "      <td>2.580729</td>\n",
              "      <td>-0.058139</td>\n",
              "      <td>-3.520332</td>\n",
              "      <td>0.759402</td>\n",
              "      <td>1.219977</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.830112</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.118711</td>\n",
              "      <td>1.994407</td>\n",
              "      <td>-0.002166</td>\n",
              "      <td>-3.159704</td>\n",
              "      <td>0.678700</td>\n",
              "      <td>14.635369</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.945678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.195685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.371506</td>\n",
              "      <td>3.442730</td>\n",
              "      <td>-0.101005</td>\n",
              "      <td>-2.704327</td>\n",
              "      <td>0.718457</td>\n",
              "      <td>1.212908</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.829802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.339582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.966335</td>\n",
              "      <td>3.040929</td>\n",
              "      <td>0.095253</td>\n",
              "      <td>-2.696737</td>\n",
              "      <td>0.641992</td>\n",
              "      <td>3.244121</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.871734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.297730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.278932</td>\n",
              "      <td>1.964991</td>\n",
              "      <td>0.098736</td>\n",
              "      <td>-3.152634</td>\n",
              "      <td>0.533742</td>\n",
              "      <td>0.622869</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.807908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.266938</td>\n",
              "      <td>2.181060</td>\n",
              "      <td>0.122408</td>\n",
              "      <td>-2.323979</td>\n",
              "      <td>0.483376</td>\n",
              "      <td>2.016342</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.850270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.320058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.270484</td>\n",
              "      <td>3.599731</td>\n",
              "      <td>-0.048192</td>\n",
              "      <td>-3.328103</td>\n",
              "      <td>0.829805</td>\n",
              "      <td>4.899556</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.895038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.270636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   spoken_kurtosis  spoken_max  spoken_mean  spoken_min  spoken_std  \\\n",
              "0         4.109109    3.746517     0.037989   -2.907489    0.640406   \n",
              "1         3.147835    3.410470     0.142919   -2.815631    0.707371   \n",
              "2         3.937611    3.167490     0.038646   -3.934161    0.699209   \n",
              "3         3.697519    2.580729    -0.058139   -3.520332    0.759402   \n",
              "4         2.118711    1.994407    -0.002166   -3.159704    0.678700   \n",
              "5         2.371506    3.442730    -0.101005   -2.704327    0.718457   \n",
              "6         3.966335    3.040929     0.095253   -2.696737    0.641992   \n",
              "7         4.278932    1.964991     0.098736   -3.152634    0.533742   \n",
              "8         3.266938    2.181060     0.122408   -2.323979    0.483376   \n",
              "9         2.270484    3.599731    -0.048192   -3.328103    0.829805   \n",
              "\n",
              "   written_kurtosis  written_max  written_mean  written_min  written_std  \n",
              "0          6.258335          1.0      0.908298          0.0     0.252658  \n",
              "1          1.328988          1.0      0.830687          0.0     0.334427  \n",
              "2          1.112804          1.0      0.824165          0.0     0.347787  \n",
              "3          1.219977          1.0      0.830112          0.0     0.344895  \n",
              "4         14.635369          1.0      0.945678          0.0     0.195685  \n",
              "5          1.212908          1.0      0.829802          0.0     0.339582  \n",
              "6          3.244121          1.0      0.871734          0.0     0.297730  \n",
              "7          0.622869          1.0      0.807908          0.0     0.368778  \n",
              "8          2.016342          1.0      0.850270          0.0     0.320058  \n",
              "9          4.899556          1.0      0.895038          0.0     0.270636  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzWttZ_L-a6O",
        "colab_type": "text"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CclpDnAw-a6O",
        "colab_type": "code",
        "outputId": "1b8fd02e-99bc-41c5-8730-aa9c59ee637f",
        "colab": {}
      },
      "source": [
        "X_val_final_cols = {'written_mean':pd.Series(written_val_mean),\n",
        "                    'written_min':pd.Series(written_val_min),\n",
        "                    'written_max':pd.Series(written_val_max),\n",
        "                    'written_std':pd.Series(written_val_std),\n",
        "                    'written_kurtosis':pd.Series(written_val_kurtosis),\n",
        "                    'spoken_mean':pd.Series(spoken_val_mean),\n",
        "                    'spoken_min':pd.Series(spoken_val_min),\n",
        "                    'spoken_max':pd.Series(spoken_val_max), \n",
        "                    'spoken_std':pd.Series(spoken_val_std),\n",
        "                    'spoken_kurtosis':pd.Series(spoken_val_kurtosis)}\n",
        "\n",
        "X_val_final = pd.DataFrame(X_val_final_cols)\n",
        "X_val_final.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spoken_kurtosis</th>\n",
              "      <th>spoken_max</th>\n",
              "      <th>spoken_mean</th>\n",
              "      <th>spoken_min</th>\n",
              "      <th>spoken_std</th>\n",
              "      <th>written_kurtosis</th>\n",
              "      <th>written_max</th>\n",
              "      <th>written_mean</th>\n",
              "      <th>written_min</th>\n",
              "      <th>written_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.342231</td>\n",
              "      <td>1.833920</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>-4.246489</td>\n",
              "      <td>0.685025</td>\n",
              "      <td>4.498108</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.892832</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.265955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.926089</td>\n",
              "      <td>2.936393</td>\n",
              "      <td>-0.023044</td>\n",
              "      <td>-2.557086</td>\n",
              "      <td>0.635517</td>\n",
              "      <td>7.754924</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.917987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.244437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.105262</td>\n",
              "      <td>2.700852</td>\n",
              "      <td>0.023705</td>\n",
              "      <td>-2.503429</td>\n",
              "      <td>0.638709</td>\n",
              "      <td>3.330619</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.873865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.294804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.368004</td>\n",
              "      <td>2.241257</td>\n",
              "      <td>0.035596</td>\n",
              "      <td>-2.972858</td>\n",
              "      <td>0.611129</td>\n",
              "      <td>2.081774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.851045</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.321656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.564494</td>\n",
              "      <td>2.480719</td>\n",
              "      <td>0.003324</td>\n",
              "      <td>-2.887304</td>\n",
              "      <td>0.733821</td>\n",
              "      <td>6.162422</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.905072</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.256116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.815722</td>\n",
              "      <td>6.294796</td>\n",
              "      <td>-0.260403</td>\n",
              "      <td>-7.697091</td>\n",
              "      <td>1.168023</td>\n",
              "      <td>1.861682</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.845928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.329028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.997747</td>\n",
              "      <td>2.323132</td>\n",
              "      <td>0.091725</td>\n",
              "      <td>-3.508085</td>\n",
              "      <td>0.635473</td>\n",
              "      <td>3.375232</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.875005</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.298929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.961801</td>\n",
              "      <td>3.352081</td>\n",
              "      <td>0.086230</td>\n",
              "      <td>-2.514017</td>\n",
              "      <td>0.627304</td>\n",
              "      <td>10.907311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.932923</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.229954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.340738</td>\n",
              "      <td>2.643023</td>\n",
              "      <td>0.147902</td>\n",
              "      <td>-2.533336</td>\n",
              "      <td>0.502528</td>\n",
              "      <td>7.467469</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.919153</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.798865</td>\n",
              "      <td>3.198134</td>\n",
              "      <td>0.118474</td>\n",
              "      <td>-2.424817</td>\n",
              "      <td>0.612269</td>\n",
              "      <td>6.462865</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   spoken_kurtosis  spoken_max  spoken_mean  spoken_min  spoken_std  \\\n",
              "0         4.342231    1.833920     0.007023   -4.246489    0.685025   \n",
              "1         2.926089    2.936393    -0.023044   -2.557086    0.635517   \n",
              "2         3.105262    2.700852     0.023705   -2.503429    0.638709   \n",
              "3         3.368004    2.241257     0.035596   -2.972858    0.611129   \n",
              "4         2.564494    2.480719     0.003324   -2.887304    0.733821   \n",
              "5         6.815722    6.294796    -0.260403   -7.697091    1.168023   \n",
              "6         5.997747    2.323132     0.091725   -3.508085    0.635473   \n",
              "7         3.961801    3.352081     0.086230   -2.514017    0.627304   \n",
              "8         5.340738    2.643023     0.147902   -2.533336    0.502528   \n",
              "9         3.798865    3.198134     0.118474   -2.424817    0.612269   \n",
              "\n",
              "   written_kurtosis  written_max  written_mean  written_min  written_std  \n",
              "0          4.498108          1.0      0.892832          0.0     0.265955  \n",
              "1          7.754924          1.0      0.917987          0.0     0.244437  \n",
              "2          3.330619          1.0      0.873865          0.0     0.294804  \n",
              "3          2.081774          1.0      0.851045          0.0     0.321656  \n",
              "4          6.162422          1.0      0.905072          0.0     0.256116  \n",
              "5          1.861682          1.0      0.845928          0.0     0.329028  \n",
              "6          3.375232          1.0      0.875005          0.0     0.298929  \n",
              "7         10.907311          1.0      0.932923          0.0     0.229954  \n",
              "8          7.467469          1.0      0.919153          0.0     0.222012  \n",
              "9          6.462865          1.0      0.910324          0.0     0.257152  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roVmcrUL-a6P",
        "colab_type": "text"
      },
      "source": [
        "# Oversampling\n",
        "we want to upsample our true examples to match our false examples.\n",
        "<br>\n",
        "therefore we used \"imblearn.over_sampling\" to get a new dataset consisting out of:\n",
        "<br>\n",
        "50% true and 50% false "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNzAINgi-a6Q",
        "colab_type": "code",
        "outputId": "4eb88ad3-1f2e-411a-9b72-9690b0e14b8f",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({False: 32369, True: 3631})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXLVYpJG-a6R",
        "colab_type": "code",
        "outputId": "d1d65153-1ae8-4d29-ed7a-4c6535d34775",
        "colab": {}
      },
      "source": [
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_final_resampled, y_train_resampled = oversampler.fit_resample(X_train_final, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train_resampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({False: 32369, True: 32369})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEjEH8Ib-a6T",
        "colab_type": "text"
      },
      "source": [
        "#### pass valid input, resampled input and label back to:\n",
        "\n",
        "- x_valid = X_val_final\n",
        "- x_train_final = input\n",
        "<br>\n",
        "- y_train = label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q2MOUWX-a6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_final = X_train_final_resampled\n",
        "X_valid = X_val_final\n",
        "y_train = y_train_resampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krMZ4FtV-a6V",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHqDBWHj-a6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler  \n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq3hHL7-a6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed = 1234"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znBmHhJI-a6Y",
        "colab_type": "text"
      },
      "source": [
        "### Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2c-Of67-a6Y",
        "colab_type": "text"
      },
      "source": [
        "Always predict the most frequent class (`False`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO82u6vN-a6Z",
        "colab_type": "code",
        "outputId": "c3a7dd5a-68f4-4924-b386-09b7f0c242a8",
        "colab": {}
      },
      "source": [
        "classifier = DummyClassifier(random_state=random_seed, strategy=\"most_frequent\")\n",
        "classifier.fit(X_train_final, y_train) \n",
        "\n",
        "y_pred = classifier.predict(X_val_final)\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
        "clf_report = classification_report(y_valid, y_pred)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(clf_report) \n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8092    0]\n",
            " [ 908    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95      8092\n",
            "        True       0.00      0.00      0.00       908\n",
            "\n",
            "    accuracy                           0.90      9000\n",
            "   macro avg       0.45      0.50      0.47      9000\n",
            "weighted avg       0.81      0.90      0.85      9000\n",
            "\n",
            "accuracy:  0.8991111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\u913525\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2H6K55D-a6a",
        "colab_type": "text"
      },
      "source": [
        "# Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YklIByN4-a6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = Normalizer()  \n",
        "scaler.fit(X_train_final)\n",
        "X_train_final = scaler.transform(X_train_final)  \n",
        "X_valid = scaler.transform(X_valid) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqJ1nED7-a6d",
        "colab_type": "text"
      },
      "source": [
        "# Train, Predict and Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF4Z0RP2-a6e",
        "colab_type": "text"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFf1qVES-a6e",
        "colab_type": "code",
        "outputId": "1fa9987f-f87f-412c-c376-009b2201c754",
        "colab": {}
      },
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=15)  \n",
        "classifier.fit(X_train_final, y_train) \n",
        "\n",
        "y_pred = classifier.predict(X_val_final)\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
        "clf_report = classification_report(y_valid, y_pred)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(clf_report) \n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4394 3698]\n",
            " [ 489  419]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.54      0.68      8092\n",
            "        True       0.10      0.46      0.17       908\n",
            "\n",
            "    accuracy                           0.53      9000\n",
            "   macro avg       0.50      0.50      0.42      9000\n",
            "weighted avg       0.82      0.53      0.63      9000\n",
            "\n",
            "accuracy:  0.5347777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgw8mcTf-a6g",
        "colab_type": "text"
      },
      "source": [
        "### SVC "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2D0M8NG-a6g",
        "colab_type": "code",
        "outputId": "60496f2f-28e4-4b8d-a6bc-a6075a052c04",
        "colab": {}
      },
      "source": [
        "classifier = SVC(gamma = 'auto', random_state=random_seed) \n",
        "classifier.fit(X_train_final, y_train) \n",
        "\n",
        "y_pred = classifier.predict(X_val_final)\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
        "clf_report = classification_report(y_valid, y_pred)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(clf_report) \n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-28-a7d05f062b79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwup0KmC-a6h",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2gGBfuE-a6i",
        "colab_type": "code",
        "outputId": "d783d993-1d22-4a75-d31a-a91298d45809",
        "colab": {}
      },
      "source": [
        "classifier = RandomForestClassifier(n_estimators = 200, random_state=random_seed, n_jobs=-2)\n",
        "classifier.fit(X_train_final, y_train) \n",
        "\n",
        "y_pred = classifier.predict(X_val_final)\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
        "clf_report = classification_report(y_valid, y_pred)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(clf_report) \n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8092    0]\n",
            " [ 908    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95      8092\n",
            "        True       0.00      0.00      0.00       908\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      9000\n",
            "   macro avg       0.45      0.50      0.47      9000\n",
            "weighted avg       0.81      0.90      0.85      9000\n",
            "\n",
            "accuracy:  0.8991111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/ThierryLobato/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WYl9UGy-a6j",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG5cNTt4-a6k",
        "colab_type": "code",
        "outputId": "bc9f2bef-9049-445a-dfbb-c4976470b12b",
        "colab": {}
      },
      "source": [
        "classifier = LogisticRegression(random_state=random_seed)\n",
        "classifier.fit(X_train_final, y_train) \n",
        "\n",
        "y_pred = classifier.predict(X_val_final)\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
        "clf_report = classification_report(y_valid, y_pred)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(clf_report) \n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8092    0]\n",
            " [ 908    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95      8092\n",
            "        True       0.00      0.00      0.00       908\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      9000\n",
            "   macro avg       0.45      0.50      0.47      9000\n",
            "weighted avg       0.81      0.90      0.85      9000\n",
            "\n",
            "accuracy:  0.8991111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/ThierryLobato/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/Users/ThierryLobato/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvFAGvT3-a6m",
        "colab_type": "text"
      },
      "source": [
        "### MultiLayerPerceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvkMuhI5-a6n",
        "colab_type": "code",
        "outputId": "e320a4db-38ae-4a52-e6d7-3ef16f709a6f",
        "colab": {}
      },
      "source": [
        "classifier = MLPClassifier(random_state=random_seed)\n",
        "classifier.fit(X_train_final, y_train) \n",
        "\n",
        "y_pred = classifier.predict(X_val_final)\n",
        "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
        "clf_report = classification_report(y_valid, y_pred)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(conf_matrix)\n",
        "print(clf_report) \n",
        "print(\"accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8092    0]\n",
            " [ 908    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      1.00      0.95      8092\n",
            "        True       0.00      0.00      0.00       908\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      9000\n",
            "   macro avg       0.45      0.50      0.47      9000\n",
            "weighted avg       0.81      0.90      0.85      9000\n",
            "\n",
            "accuracy:  0.8991111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/ThierryLobato/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TNdiFXo-a6p",
        "colab_type": "text"
      },
      "source": [
        "# Gridsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5pPfEMR-a6p",
        "colab_type": "text"
      },
      "source": [
        "all classifiers perform poorly.. RF performs slightly better... now try gridsearch over the hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaC5VcA0-a6p",
        "colab_type": "text"
      },
      "source": [
        "The following cell takes quite a long time (~1hr) to run, you can also skip this cell and read the results in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hhgXCVEU-a6q",
        "colab_type": "code",
        "outputId": "a240e337-7bc1-4686-b4d3-5ee88cbcdd9e",
        "colab": {}
      },
      "source": [
        "classifier = RandomForestClassifier(n_estimators=200, random_state=random_seed, n_jobs=-2)\n",
        "\n",
        "param_grid = {\"max_depth\": [5, 10, 15, 20, 25],\n",
        "              \"min_samples_split\": [2, 5, 10, 25, 35, 50, 100, 250],\n",
        "              \"min_samples_leaf\": [1, 5, 10, 35, 100]}\n",
        "\n",
        "gridsearch = GridSearchCV(estimator=classifier,\n",
        "                          param_grid=param_grid,\n",
        "                          scoring=[\"accuracy\", \"roc_auc\"],\n",
        "                          cv=5, \n",
        "                          n_jobs=-2, \n",
        "                          verbose=5,\n",
        "                          return_train_score=False,\n",
        "                          refit=False)\n",
        "\n",
        "gridsearch.fit(X_train_final, y_train) \n",
        "\n",
        "cv_results = pd.DataFrame(gridsearch.cv_results_).sort_values(by=[\"mean_test_accuracy\",\"mean_test_roc_auc\"], ascending=False)\n",
        "cv_results.to_csv(\"gridsearch_results.csv\")\n",
        "cv_results[[\"params\", \"mean_test_roc_auc\", \"mean_test_accuracy\"]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:   22.5s\n",
            "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-2)]: Done 148 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=-2)]: Done 274 tasks      | elapsed: 15.8min\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b27476da6bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           refit=False)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_test_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mean_test_roc_auc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1ro3iP6-a6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_results = pd.read_csv(\"gridsearch_results.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es9faXce-a6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_results[[\"params\", \"mean_test_roc_auc\", \"mean_test_accuracy\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjKhAE4g-a6u",
        "colab_type": "text"
      },
      "source": [
        "## Refit on Entire Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_nlyQfu-a6v",
        "colab_type": "text"
      },
      "source": [
        "- preprocess the test data with `extract_summary_stats` functions and repeat steps 2,3,4\n",
        "- do the same for the entire training dataset, so that there is no train/val split anymore\n",
        "- fit model with best parameters on the entire dataset (train + val) \n",
        "- predict on test set\n",
        "- submit results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0DJTprC-a6v",
        "colab_type": "text"
      },
      "source": [
        "#### Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijxD3ALV-a6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_written = numpy.load(\"written_test.npy\", allow_pickle=True)\n",
        "X_test_spoken = numpy.load(\"spoken_test.npy\", allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNKEMwbR-a6x",
        "colab_type": "text"
      },
      "source": [
        "#### Load train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc3JDuQf-a6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "written_train_full = numpy.load(\"written_train.npy\", allow_pickle=True)\n",
        "spoken_train_full = numpy.load(\"spoken_train.npy\", allow_pickle=True)\n",
        "y_train_full = numpy.load(\"match_train.npy\", allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGb6ynIi-a6z",
        "colab_type": "text"
      },
      "source": [
        "#### step 2: Preprocess test data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB0LOSfE-a6z",
        "colab_type": "code",
        "outputId": "353d46f5-a0f1-4c3d-dbd7-5999b5ec391a",
        "colab": {}
      },
      "source": [
        "X_test_written_full = extract_summary_stats_written(X_test_written)\n",
        "X_test_spoken_full = extract_summary_stats_spoken(X_test_spoken)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24759229427010582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QKjyNh5-a60",
        "colab_type": "text"
      },
      "source": [
        "#### step 2: Preprocess train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-3ojEXt-a61",
        "colab_type": "code",
        "outputId": "4bb756cb-9304-4e0c-fb4e-ffd31cda86eb",
        "colab": {}
      },
      "source": [
        "X_train_written_full = extract_summary_stats_written(written_train_full)\n",
        "X_train_spoken_full = extract_summary_stats_spoken(spoken_train_full)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0050469198705037546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkXBtvvR-a62",
        "colab_type": "text"
      },
      "source": [
        "#### step 3: extract all summaries for test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFtQG65N-a62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "written_test_mean, written_test_min, written_test_max, written_test_std, written_test_kurtosis = X_test_written_full\n",
        "spoken_test_mean, spoken_test_min, spoken_test_max, spoken_test_std, spoken_test_kurtosis = X_test_spoken_full"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADcanP6W-a66",
        "colab_type": "text"
      },
      "source": [
        "#### step 3: extract all summaries for train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e-h1rGX-a67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "written_mean_full, written_min_full, written_max_full, written_std_full, written_kurtosis_full = X_train_written_full\n",
        "spoken_mean_full, spoken_min_full, spoken_max_full, spoken_std_full, spoken_kurtosis_full = X_train_spoken_full"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBdDy5Ra-a69",
        "colab_type": "text"
      },
      "source": [
        "#### step 4: create panda frame for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsDcq92w-a6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_final_cols = {'written_mean':pd.Series(written_test_mean),\n",
        "                      'written_min':pd.Series(written_test_min),\n",
        "                      'written_max':pd.Series(written_test_max),\n",
        "                      'written_std':pd.Series(written_test_std),\n",
        "                      'written_kurtosis':pd.Series(written_test_kurtosis),\n",
        "                      'spoken_mean':pd.Series(spoken_test_mean),\n",
        "                      'spoken_min':pd.Series(spoken_test_min),\n",
        "                      'spoken_max':pd.Series(spoken_test_max), \n",
        "                      'spoken_std':pd.Series(spoken_test_std),\n",
        "                      'spoken_kurtosis':pd.Series(spoken_test_kurtosis)}\n",
        "\n",
        "\n",
        "X_test_final = pd.DataFrame(X_test_final_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2pBzNOf-a6_",
        "colab_type": "text"
      },
      "source": [
        "#### step 4: create panda frame for train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0SHU0he-a6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_final_full = {'written_mean':pd.Series(written_mean_full),\n",
        "                      'written_min':pd.Series(written_min_full),\n",
        "                      'written_max':pd.Series(written_max_full),\n",
        "                      'written_std':pd.Series(written_std_full),\n",
        "                      'written_kurtosis':pd.Series(written_kurtosis_full),\n",
        "                      'spoken_mean':pd.Series(spoken_mean_full),\n",
        "                      'spoken_min':pd.Series(spoken_min_full),\n",
        "                      'spoken_max':pd.Series(spoken_max_full), \n",
        "                      'spoken_std':pd.Series(spoken_std_full),\n",
        "                      'spoken_kurtosis':pd.Series(spoken_kurtosis_full)}\n",
        "\n",
        "\n",
        "X_train_full = pd.DataFrame(X_train_final_full)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyThmesf-a7B",
        "colab_type": "code",
        "outputId": "7ad7a0fc-d5bf-42cb-a5d5-22f790a0a479",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_final_resampled, y_train_resampled = oversampler.fit_resample(X_train_full, y_train_full)\n",
        "print('Resampled dataset shape %s' % Counter(y_train_resampled))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({False: 40461, True: 40461})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXSBCKdy-a7D",
        "colab_type": "text"
      },
      "source": [
        "#### pass full training data, training label & test data to below names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Bl6MF9-a7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_full = X_test_final\n",
        "X_train_full = X_train_final_resampled\n",
        "y_train_full = y_train_resampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcp6dTP0-a7L",
        "colab_type": "text"
      },
      "source": [
        "#### Fit with best parameters on all training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wTGLXmS-a7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_params = cv_results.best_params\n",
        "classifier = RandomForestClassifier(**best_params, n_estimators=200, random_state=random_seed, n_jobs=-2)\n",
        "\n",
        "classifier.fit(X_train_full, y_train_full)\n",
        "\n",
        "y_pred = classifier.predict(X_test_full)\n",
        "numpy.save(\"result\", y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS0Iyay3-a7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}